{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zeno_client import ZenoClient, ZenoMetric\n",
    "import pandas as pd\n",
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "import re\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f\"../outputs/bbh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = os.listdir(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with_image', 'without_image']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload base dataset\n",
    "df = pd.read_json(os.path.join(OUTPUT_DIR, models[0], \"output.jsonl\"), lines=True)\n",
    "df['task_qid'] = df['task'] +'_'+ df['qid'].astype(str)\n",
    "woi_df = pd.read_json(os.path.join(OUTPUT_DIR, models[1], \"output.jsonl\"), lines=True)\n",
    "\n",
    "df['image'] = df.apply(lambda x: f'https://automated-vqa.s3.amazonaws.com/bbh/'+str(x['qid'])+'.jpg', axis=1)\n",
    "base_df = pd.DataFrame({\n",
    "    \"qid\": df[\"task_qid\"],\n",
    "    \"image\": df['image'],\n",
    "    \"question\": df[\"question\"],\n",
    "    \"answer\": df[\"answer\"].astype(str) ,\n",
    "    \"with_image_correct\": df[\"is_correct\"].astype(bool),\n",
    "    \"without_image_correct\": woi_df[\"is_correct\"].astype(bool)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/tir/projects/tir4/users/sakter/anaconda3/envs/bleed/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package zeno-client is out of date. Your version is 0.1.13, the latest is 0.1.14.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "zeno_client = ZenoClient(\"zen_P4CK880bWHV2dJLbAenb0r8Gf6QNLdTXhSkkHqPDm4I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated project.\n",
      "Access your project at  https://hub.zenoml.com/project/81da4d46-c460-47d4-a011-1509ac260806/VLM%3A%20BBH\n"
     ]
    }
   ],
   "source": [
    "base_df[\"data\"] = base_df.apply(\n",
    "    lambda row: {\"question\": row.question, \"image\": row.image}, axis=1\n",
    ")\n",
    "\n",
    "project = zeno_client.create_project(\n",
    "    name=f\"VLM: BBH\",\n",
    "    description=f\"Evaluation of VLM on BBH dataset\",\n",
    "    view={\n",
    "        \"data\": {\n",
    "            \"type\": \"vstack\",\n",
    "            \"keys\": {\"question\": {\"type\": \"text\"}, \"image\": {\"type\": \"image\"}},\n",
    "        },\n",
    "        \"label\": {\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"output\": {\n",
    "            \"type\": \"markdown\"\n",
    "        }\n",
    "    },\n",
    "    public=True,\n",
    "    metrics=[\n",
    "        ZenoMetric(name=\"Accuracy Strict Match\", type=\"mean\", columns=[\"is_correct\"]),\n",
    "        ZenoMetric(name=\"Accuracy\", type=\"mean\", columns=[\"is_correct_last\"])\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0469cc69a8aa4f429198b24bb9a5756e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data\n"
     ]
    }
   ],
   "source": [
    "project.upload_dataset(base_df, id_column=\"qid\", data_column=\"data\", label_column=\"answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1a94789dc24cf6abe6c87d00f9523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b478d85e300f41978c89b7ebc8f2b974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def answer_type(answer):\n",
    "    pattern = '[-+]?(?:[0-9,]*\\.*\\d+)'\n",
    "    soln = re.findall(pattern, answer) \n",
    "    if answer.startswith('(') and answer.endswith(')'):\n",
    "        return 'MCQ'\n",
    "    elif answer == 'yes' or answer == 'Yes' or answer == 'No' or answer == 'no':\n",
    "        return 'Yes/No'\n",
    "    elif answer == 'true' or answer == 'True' or answer == 'False' or answer == 'false':\n",
    "        return 'True/False'\n",
    "    elif answer == 'valid' or answer == 'Valid' or answer == 'invalid' or answer == 'Invalid':\n",
    "        return 'Valid/Invalid'\n",
    "    elif len(soln) > 0:\n",
    "        return 'Digit'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "    \n",
    "for model in models:\n",
    "    df = pd.read_json(os.path.join(OUTPUT_DIR, model, \"output.jsonl\"), lines=True)\n",
    "    df['task_qid'] = df['task'] +'_'+ df['qid'].astype(str)\n",
    "    if model == 'with_image':\n",
    "        df['image'] = df.apply(lambda x: 'https://automated-vqa.s3.amazonaws.com/mawpsmultiarith/dummy_img.png', axis=1)\n",
    "    if model == 'mixtral':\n",
    "        output_df = pd.DataFrame({\n",
    "            \"qid\": df[\"task_qid\"],\n",
    "            \"task\": df[\"task\"],\n",
    "            \"output\": df.apply(lambda x: f\"{x['response'].split('Q:')[0]}\\n\\n**{x['predict']}**\", axis=1),\n",
    "            \"output_last\": df.apply(lambda x: f\"{x['predict_last']}\", axis=1),\n",
    "            \"output_type\": df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1),\n",
    "            \"question_length\": df.apply(lambda x: len(x['question'].split('Q:')[1].strip().split(' ')), axis=1),\n",
    "            \"output_length\": df.apply(lambda x: len(x['response'].split('Q:')[0].split(' ')), axis=1),\n",
    "            \"is_correct\": df[\"is_correct\"].astype(bool),\n",
    "            \"is_correct_last\": df[\"is_correct_last\"].astype(bool),\n",
    "        })\n",
    "    else:\n",
    "        output_df = pd.DataFrame({\n",
    "            \"qid\": df[\"task_qid\"],\n",
    "            \"task\": df[\"task\"],\n",
    "            \"output\": df.apply(lambda x: f\"{x['response'].split('Q:')[0]}\\n\\n**{x['predict']}**\", axis=1),\n",
    "            \"output_last\": df.apply(lambda x: f\"{x['predict_last']}\", axis=1),\n",
    "            \"output_type\": df.apply(lambda x: f\"{answer_type(x['answer'])}\", axis=1),\n",
    "            \"question_length\": df.apply(lambda x: len(x['question'].split('Q:')[1].strip().split(' ')), axis=1),\n",
    "            \"output_length\": df.apply(lambda x: len(x['response'].split(' ')), axis=1),\n",
    "            \"is_correct\": df[\"is_correct\"].astype(bool),\n",
    "            \"is_correct_last\": df[\"is_correct_last\"].astype(bool)\n",
    "        })\n",
    "    if model == 'gpt-4-1106-preview':\n",
    "        model = 'gpt-4-turbo'\n",
    "    project.upload_system(output_df, name=model, id_column=\"qid\", output_column=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bleed",
   "language": "python",
   "name": "bleed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
